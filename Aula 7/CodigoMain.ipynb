{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QTdIPWEkwgqd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#instalando a biblioteca Llama index\n",
        "!pip install -q llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GtvaLGG1xMBp"
      },
      "outputs": [],
      "source": [
        "# biblioteca para permitir a leitura de arquivos\n",
        "from llama_index.core import SimpleDirectoryReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NTskzu2kxhU_"
      },
      "outputs": [],
      "source": [
        "documentos = SimpleDirectoryReader(input_dir='../Aula 7/arquivo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KIAppBoyXek",
        "outputId": "79a6aa4a-3284-4ebc-c940-d213e768746c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[WindowsPath('c:/Users/47341687843/Documents/ChatBot/ChatBot/Aula 7/../Aula 7/arquivo/doc_info_agricultura.pdf')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documentos.input_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Onj71K3EyvEd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 8 0 (offset 0)\n",
            "Ignoring wrong pointing object 11 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "docs = documentos.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMByOSxGzUnw",
        "outputId": "b6e5175c-5d53-4b86-937a-ba68f499c5df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id_': '659cc045-ee3b-43d2-b703-c9283e5096f4',\n",
              " 'embedding': None,\n",
              " 'metadata': {'page_label': '1',\n",
              "  'file_name': 'doc_info_agricultura.pdf',\n",
              "  'file_path': 'c:\\\\Users\\\\47341687843\\\\Documents\\\\ChatBot\\\\ChatBot\\\\Aula 7\\\\..\\\\Aula 7\\\\arquivo\\\\doc_info_agricultura.pdf',\n",
              "  'file_type': 'application/pdf',\n",
              "  'file_size': 30901,\n",
              "  'creation_date': '2025-03-19',\n",
              "  'last_modified_date': '2025-03-19'},\n",
              " 'excluded_embed_metadata_keys': ['file_name',\n",
              "  'file_type',\n",
              "  'file_size',\n",
              "  'creation_date',\n",
              "  'last_modified_date',\n",
              "  'last_accessed_date'],\n",
              " 'excluded_llm_metadata_keys': ['file_name',\n",
              "  'file_type',\n",
              "  'file_size',\n",
              "  'creation_date',\n",
              "  'last_modified_date',\n",
              "  'last_accessed_date'],\n",
              " 'relationships': {},\n",
              " 'metadata_template': '{key}: {value}',\n",
              " 'metadata_separator': '\\n',\n",
              " 'text_resource': MediaResource(embeddings=None, data=None, text='Guia de Preparo do Solo para Plantio Informações Gerais P: Qual a importância do preparo adequado do solo? R: O preparo adequado do solo garante que as plantas tenham acesso aos nutrientes necessários, além de melhorar a retenção de água e a aeração, fatores essenciais para o crescimento saudável. P: Quais fatores devem ser considerados ao preparar o solo para o plantio? R: Os principais fatores incluem o tipo de solo, a umidade ideal, o pH, a compactação e a adubação adequada para cada cultura. Tipos de Solo e Seu Tratamento P: Quais os principais tipos de solo e como prepará-los? R: Existem diversos tipos de solo, cada um com características específicas e tratamentos recomendados: • Solo Arenoso: Drenagem rápida, baixo teor de nutrientes. Recomenda-se adição de matéria orgânica e irrigação frequente. • Solo Argiloso: Retém muita água, pode compactar facilmente. Aéreação e adição de areia podem melhorar a drenagem. • Solo Calcário: Alto pH, pouca disponibilidade de micronutrientes. Pode ser corrigido com adubação orgânica e fertilizantes ácidos. Sensores para Monitoramento da Umidade do Solo P: Quais sensores podem ser usados para monitorar a umidade do solo? R: Existem diversas tecnologias para medir a umidade do solo, entre elas: • Sensor Capacitivo de Umidade do Solo: Mede a variação da capacitância conforme o nível de umidade. • Sensor Resistivo de Umidade: Mede a condutividade elétrica do solo, variando conforme a umidade. • Sensor TDR (Time Domain Reflectometry): Utiliza pulsos eletromagnéticos para calcular a umidade com alta precisão. • Sondas de Tensiômetro: Medem a tensão com que a água está sendo retida no solo, indicando o nível de umidade disponível para as plantas. Esses sensores são fundamentais para o manejo eficiente da irrigação e para evitar estresse hídrico das plantas. Umidade e pH Ideais P: Como medir e ajustar a umidade do solo? R: A umidade pode ser medida com sensores ou testes simples (amassando o solo na mão). Para solos muito secos, a irrigação regular é essencial; para solos muito úmidos, drenagem adequada deve ser aplicada. ', path=None, url=None, mimetype=None),\n",
              " 'image_resource': None,\n",
              " 'audio_resource': None,\n",
              " 'video_resource': None,\n",
              " 'text_template': '{metadata_str}\\n\\n{content}'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].__dict__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hSmhVKqLzbZ8"
      },
      "outputs": [],
      "source": [
        "# importando a biblioteca\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "node_parser= SentenceSplitter(chunk_size=1200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2e9de5fdd7d74fc1b8bf553dbf8b56cf",
            "54309e2d38bf4df8953bc92cecd93ed9",
            "ba3285e294a84338887f60634f56011d",
            "660a926516784b0d8445a924f4241bd0",
            "32567f36e10146359382240e95a25a4f",
            "b964d049203448d484d053ba74d4d4df",
            "a0ac07d44c174e0eb433663688d29161",
            "a31764037e2b45deac32374af85feb4f",
            "449d31336daf4547b421b0e9ff38168b",
            "8cad7f9da6c34a589242394eb0db56ef",
            "2c33dc8a608a4b6f9bef6f07edff80d7"
          ]
        },
        "id": "wcoruETm2pv2",
        "outputId": "9bb4cedc-0802-43ea-ac83-07419994917c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\47341687843\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Parsing nodes: 100%|██████████| 3/3 [00:00<00:00, 1795.51it/s]\n"
          ]
        }
      ],
      "source": [
        "nodes = node_parser.get_nodes_from_documents(docs,show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TB5Bq8GU43XV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#instalaçao do hugging face\n",
        "!pip install -q llama-index-embeddings-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rslQYgAR6EUt"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kY4BSvjt6ZnF"
      },
      "outputs": [],
      "source": [
        "# Classe personalizada para integrar ao Chroma DB\n",
        "\n",
        "class ChromaEmbeddingWrapper:\n",
        "  def __init__(self,model_name:str): # inicializa com o modelo embedding\n",
        "    self.model = HuggingFaceEmbedding(model_name = model_name)\n",
        "\n",
        "\n",
        "  def __call__(self,input): # Converte a entrada para o formato compativel com o HuggingFace\n",
        "    return self.model.embed(input)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz3Owmy_72tH",
        "outputId": "3d1ad1ea-051f-4e45-f656-404d515d4e55"
      },
      "outputs": [],
      "source": [
        "embed_model_chroma= ChromaEmbeddingWrapper(model_name='intfloat/multilingual-e5-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SHXYAcyJ8oTq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [5 lines of output]\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_ext\n",
            "      building 'hnswlib' extension\n",
            "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for chroma-hnswlib\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: C:\\Program Files\\Python313\\python.exe -m pip install --upgrade pip\n",
            "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (chroma-hnswlib)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting chromadb\n",
            "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Using cached fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (2.2.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Using cached posthog-3.21.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Using cached onnxruntime-1.21.0-cp313-cp313-win_amd64.whl.metadata (4.9 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Using cached opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_sdk-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Using cached grpcio-1.71.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb)\n",
            "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Using cached kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Using cached mmh3-5.1.0-cp313-cp313-win_amd64.whl.metadata (16 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb)\n",
            "  Using cached orjson-3.10.15-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from chromadb) (0.28.1)\n",
            "Collecting rich>=10.11.0 (from chromadb)\n",
            "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Using cached starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-6.30.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: sympy in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from tokenizers>=0.13.2->chromadb) (0.29.3)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached httptools-0.6.4-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached watchfiles-1.0.4-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\47341687843\\appdata\\roaming\\python\\python313\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Using cached chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
            "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Using cached fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "Using cached grpcio-1.71.0-cp313-cp313-win_amd64.whl (4.3 MB)\n",
            "Using cached kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "Using cached mmh3-5.1.0-cp313-cp313-win_amd64.whl (41 kB)\n",
            "Using cached onnxruntime-1.21.0-cp313-cp313-win_amd64.whl (11.8 MB)\n",
            "Using cached opentelemetry_api-1.31.0-py3-none-any.whl (65 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
            "Using cached opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl (12 kB)\n",
            "Using cached opentelemetry_instrumentation-0.52b0-py3-none-any.whl (31 kB)\n",
            "Using cached opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl (16 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl (183 kB)\n",
            "Using cached opentelemetry_util_http-0.52b0-py3-none-any.whl (7.3 kB)\n",
            "Using cached opentelemetry_sdk-1.31.0-py3-none-any.whl (118 kB)\n",
            "Using cached orjson-3.10.15-cp313-cp313-win_amd64.whl (133 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached posthog-3.21.0-py2.py3-none-any.whl (79 kB)\n",
            "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "Using cached googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
            "Using cached httptools-0.6.4-cp313-cp313-win_amd64.whl (87 kB)\n",
            "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "Using cached watchfiles-1.0.4-cp313-cp313-win_amd64.whl (285 kB)\n",
            "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "Building wheels for collected packages: chroma-hnswlib\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml): started\n",
            "  Building wheel for chroma-hnswlib (pyproject.toml): finished with status 'error'\n",
            "Failed to build chroma-hnswlib\n"
          ]
        }
      ],
      "source": [
        "#instalaçao do chroma db\n",
        "#!pip install -q llama-index-vector-stores-chroma\n",
        "# !pip install --upgrade pip\n",
        "!pip install --upgrade chromadb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uhdy1iPO9kpN"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'chromadb'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#importando chroma db\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m db \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mPersistentClient(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./chroma_db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m db\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'"
          ]
        }
      ],
      "source": [
        "#importando chroma db\n",
        "import chromadb\n",
        "db = chromadb.PersistentClient(path='./chroma_db')\n",
        "chroma_client = db\n",
        "collection_name = 'documentos_serenatto'\n",
        "\n",
        "try:\n",
        " chroma_collection = chroma_client.get_or_create_collection(\n",
        "        name=collection_name,\n",
        "        embedding_function=embed_model_chroma)\n",
        "\n",
        "except Exception as e :\n",
        "  print(f'Erro ao criar coleçao {e}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rwOLnF_AIjf"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import StorageContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pvOzkFkAlPI"
      },
      "outputs": [],
      "source": [
        "#criando a coleçao do banco de dados\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFDBebEuA5DH"
      },
      "outputs": [],
      "source": [
        "embed_model = HuggingFaceEmbedding(model_name='intfloat/multilingual-e5-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCZojfSSBIbb"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvfoH4vkBebx"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex(nodes, storage_context=storage_context,embed_model = embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPbAsD0zHX1P"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import load_index_from_storage\n",
        "index = load_index_from_storage(storage_context,embed_model = embed_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMjptl9JIjFw"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "Groq_api =userdata.get('api_groq_chat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0nMZEULJwhB"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index-llms-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohscxt_fJ9sK"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.groq import Groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi68wkvZKP4j"
      },
      "outputs": [],
      "source": [
        "llms = Groq(model = 'llama3-70b-8192',api_key=Groq_api )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkjGRo30KoFc"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine(llm=llms,similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ipFiKka1LCCb",
        "outputId": "eb7e0cd1-1c56-4292-ee9f-ce9da4336854"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Trabalhamos com as seguintes variedades de café em grãos: Bourbon vermelho, Bourbon amarelo, Blend especial (Mistura de Bourbon amarelo e vermelho), Catuaí amarelo, Geisha, Yirgacheffe.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_engine.query('Quais graos estao disponiveis').response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkpXSd6OLsB1"
      },
      "outputs": [],
      "source": [
        "query_embedding = embed_model.get_text_embedding('Quais graos estao disponiveis ?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7SKFcL1MBh-",
        "outputId": "bc373b83-aac7-4d80-fb79-63268b4d4936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': [['3591a1e4-813c-45a4-b0eb-13ca928fb822',\n",
              "   '757a9a46-5ba3-4356-97f9-b192fcce7a37']],\n",
              " 'embeddings': [array([[ 0.01460024, -0.01119941, -0.00576889, ...,  0.00555894,\n",
              "          -0.0503395 ,  0.00342874],\n",
              "         [ 0.01460024, -0.01119941, -0.00576889, ...,  0.00555894,\n",
              "          -0.0503395 ,  0.00342874]])],\n",
              " 'documents': None,\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'metadatas': None,\n",
              " 'distances': [[0.3871879346745659, 0.3871879346745659]],\n",
              " 'included': [<IncludeEnum.embeddings: 'embeddings'>,\n",
              "  <IncludeEnum.distances: 'distances'>]}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chroma_collection.query(query_embedding,n_results=2,include=['distances','embeddings'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r4fbqyxM4mB"
      },
      "outputs": [],
      "source": [
        "chat_engine = index.as_chat_engine(mode='context',llm = llms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nym3nPrUNtd",
        "outputId": "73f1dadd-97ad-445e-8290-af2d472d8be3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Os grãos disponíveis são Bourbon vermelho, Bourbon amarelo, Blend especial (uma mistura de Bourbon amarelo e vermelho), Catuaí amarelo, Geisha e Yirgacheffe.\n"
          ]
        }
      ],
      "source": [
        "pergunta = chat_engine.chat('Quais graos estao disponiveis ?').response\n",
        "print(pergunta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3EDTl8n3UYYI",
        "outputId": "33f2f28c-11b0-494c-8950-9a3c3ccb5037"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Os grãos disponíveis são: Bourbon vermelho, Bourbon amarelo, Blend especial (Mistura de Bourbon amarelo e vermelho), Catuaí amarelo, Geisha e Yirgacheffe.'"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0447UiGUnvY",
        "outputId": "29c84b73-1bfd-4348-f367-53d839c6ee39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Os preços dos grãos são: Bourbon vermelho: R$ 41,00, Bourbon amarelo: R$ 43,00, Blend especial: R$ 37,50, Catuaí amarelo: R$ 55,00, Geisha: R$ 105,00, e Yirgacheffe: R$ 110,00.\n"
          ]
        }
      ],
      "source": [
        "pergunta = chat_engine.chat('Quais sao os preços dos graos ?').response\n",
        "print(pergunta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn4rcc3kUxQp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUPd-IzRUyOv",
        "outputId": "9fb32265-5507-4be3-9503-2cca860ef553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O Catuai amarelo tem doçura máxima (5/5) e corpo médio-alto (4/5) com amargor baixo (1/5). Além disso, apresenta uma acidez expressiva e notas incríveis de pitanga, desviando do tradicional.\n"
          ]
        }
      ],
      "source": [
        "pergunta = chat_engine.chat('Voce pode me dar mais detalhes sobre o Catuai amarelo ?').response\n",
        "print(pergunta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9CvV2CKVCj_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjRYFWr7VDe0",
        "outputId": "366b6b11-a617-4524-ce8d-8c4e858a7550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O preço do Catuai amarelo é R$ 55,00.\n"
          ]
        }
      ],
      "source": [
        "pergunta = chat_engine.chat('Qual o preço dele ?').response\n",
        "print(pergunta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkIHEfRbVWaJ",
        "outputId": "f2e3333e-12ee-4d1a-802c-86f2ddf0a5b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Quais graos estao disponiveis ?')]),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Os grãos disponíveis são Bourbon vermelho, Bourbon amarelo, Blend especial (uma mistura de Bourbon amarelo e vermelho), Catuaí amarelo, Geisha e Yirgacheffe.')]),\n",
              " ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Quais sao os preços dos graos ?')]),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Os preços dos grãos são: Bourbon vermelho: R$ 41,00, Bourbon amarelo: R$ 43,00, Blend especial: R$ 37,50, Catuaí amarelo: R$ 55,00, Geisha: R$ 105,00, e Yirgacheffe: R$ 110,00.')]),\n",
              " ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Voce pode me dar mais detalhes sobre o Catuai amarelo ?')]),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='O Catuai amarelo tem doçura máxima (5/5) e corpo médio-alto (4/5) com amargor baixo (1/5). Além disso, apresenta uma acidez expressiva e notas incríveis de pitanga, desviando do tradicional.')]),\n",
              " ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Qual o preço dele ?')]),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='O preço do Catuai amarelo é R$ 55,00.')])]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_engine.chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOgSibaHWcte"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.memory import ChatSummaryMemoryBuffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKqnWNVsW2u5"
      },
      "outputs": [],
      "source": [
        "memory = ChatSummaryMemoryBuffer(llm=llms,token_limit=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5TeuW_HXIbB"
      },
      "outputs": [],
      "source": [
        "chat_engine= index.as_chat_engine(\n",
        "    chat_mode = 'context',\n",
        "    llm=llms,\n",
        "    memory=memory,\n",
        "    system_prompt=('''Voce é especialista em cafes da loja Serenato, uma loja online que vende graos de cafe\n",
        "   torrados, sua funçao é tirar duvidas de forma simpatica e natural sobre os graos disponiveis''')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6lxM-puYOAB",
        "outputId": "23466e7a-e02e-484d-b903-23a5d71ee2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Olá! Bem-vindo à loja online Serenatto! Eu sou o especialista em cafés aqui. Estou aqui para ajudar a tirar suas dúvidas sobre nossos deliciosos grãos de café torrados. Qual é sua pergunta sobre nossos cafés?\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat('Ola')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OxusbWBYqli",
        "outputId": "9544ad8c-ea69-4647-fdea-b76af6d5e462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O Catuaí amarelo! É um dos nossos cafés mais exóticos e especiais. Ele possui uma doçura máxima (5/5) e um corpo médio-alto (4/5), com um amargor baixo (1/5). O que o torna realmente único é sua expressiva acidez e as notas maravilhosas de pitanga. É um café que foge do tradicional e é perfeito para quem busca uma experiência sensorial diferenciada.\n",
            "\n",
            "O processo de produção do Catuaí amarelo é fermentado, cultivado em altitude de 1.200m, com torra média. Isso lhe confere um perfil sensorial muito interessante e agradável.\n",
            "\n",
            "Se você é um amante de cafés que oferecem algo novo e emocionante, o Catuaí amarelo é uma ótima escolha. Você vai adorar sua complexidade e sua capacidade de surpreender!\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat('Voce pode me dar mais detalhes sobre o catui amarelo')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjA8zP1SY42A",
        "outputId": "efc187a2-c0dd-4b84-beae-29833b909734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O preço do Catuaí amarelo é de R$ 55,00 por pacote de 250g. É um investimento vale a pena para quem busca uma experiência de café única e de alta qualidade. Além disso, como todos os nossos cafés, o Catuaí amarelo tem uma nota SCA acima de 80, garantindo que você esteja recebendo um produto de alta qualidade.\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat('qual o preço dele')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmk43LevZDRK",
        "outputId": "6bf4f236-8538-4c74-8bb3-6bce090e77f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ChatMessage(role=<MessageRole.SYSTEM: 'system'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='It looks like we have a conversation started in Portuguese!\\n\\nTo summarize, the user greeted with \"Ola\" and the assistant responded with a warm welcome to the online store Serenatto, introducing themselves as a coffee expert. The assistant is ready to help answer any questions the user may have about their delicious roasted coffee beans.\\n\\nThe conversation so far:\\n\\nUser: Ola\\nAssistant: Olá! Bem-vindo à loja online Serenatto! Eu sou o especialista em cafés aqui. Estou aqui para ajudar a tirar suas dúvidas sobre nossos deliciosos grãos de café torrados. Qual é sua pergunta sobre nossos cafés?\\n\\nThe user then asked for more details about the \"Catui amarelo\" coffee. The assistant responded by describing the coffee\\'s characteristics, such as its high sweetness, medium-high body, and low bitterness. The assistant highlighted the coffee\\'s unique acidity and notes of pitanga, making it a perfect choice for those seeking a differentiated sensory experience.\\n\\nThe assistant also explained the production process of the Catuaí amarelo, which involves fermentation, cultivation at an altitude of 1,200m, and medium roasting. This process gives the coffee an interesting and pleasant sensory profile.\\n\\nThe assistant concluded by recommending the Catuaí amarelo to those who enjoy trying new and exciting coffee experiences, praising its complexity and ability to surprise.')]),\n",
              " ChatMessage(role=<MessageRole.USER: 'user'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='qual o preço dele')]),\n",
              " ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='O preço do Catuaí amarelo é de R$ 55,00 por pacote de 250g. É um investimento vale a pena para quem busca uma experiência de café única e de alta qualidade. Além disso, como todos os nossos cafés, o Catuaí amarelo tem uma nota SCA acima de 80, garantindo que você esteja recebendo um produto de alta qualidade.')])]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.get()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z6s3ZjRZWsu"
      },
      "outputs": [],
      "source": [
        "#resetando o chat\n",
        "chat_engine.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFvgtbXJZmaE",
        "outputId": "c78703ea-5977-473b-eab0-8927d45480ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Olá!\n",
            "\n",
            "Você está perguntando sobre o preço de um dos nossos cafés especiais, certo?\n",
            "\n",
            "Nós temos várias opções disponíveis, e os preços variam de acordo com a variedade. Aqui vão os preços de cada uma delas:\n",
            "\n",
            "* Bourbon Vermelho: R$ 41,00\n",
            "* Bourbon Amarelo: R$ 43,00\n",
            "* Blend Especial (mistura de Bourbon Amarelo e Vermelho): R$ 37,50\n",
            "* Catuaí Amarelo: R$ 55,00\n",
            "* Geisha: R$ 105,00\n",
            "* Yirgacheffe: R$ 110,00\n",
            "\n",
            "Qual variedade você está interessado em saber mais sobre?\n"
          ]
        }
      ],
      "source": [
        "response = chat_engine.chat('qual o preço dele')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wGipxalZqKj"
      },
      "outputs": [],
      "source": [
        "# implementando a interface com o Gradio\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHE6H_4SbURe"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX1ugF4YbXO1"
      },
      "outputs": [],
      "source": [
        "# Criando a função para conversar com o chatbot\n",
        "def converse_com_bot(message, chat_history):\n",
        "    response = chat_engine.chat(message)\n",
        "\n",
        "    if chat_history is None:\n",
        "        chat_history = []\n",
        "\n",
        "    chat_history.append({\"role\": \"user\", \"content\": message})\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": response.response})\n",
        "\n",
        "    return \"\", chat_history\n",
        "\n",
        "# Criando a função para resetar o chatbot\n",
        "def resetar_chat():\n",
        "    chat_engine.reset()\n",
        "    return []\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "0c-y5glzbeXd",
        "outputId": "4bf614c0-2f94-41bd-bd3a-ee56b9f2f895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a001597c67037ec64f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a001597c67037ec64f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with gr.Blocks() as app:\n",
        "\n",
        "    gr.Markdown('# Chatbot da Serenatto')\n",
        "    chatbot = gr.Chatbot(type='messages')\n",
        "    msg = gr.Textbox(label='Digite a sua mensagem')\n",
        "    limpar = gr.Button('Limpar')\n",
        "\n",
        "    msg.submit(converse_com_bot,[msg,chatbot],[msg,chatbot])\n",
        "    limpar.click(resetar_chat,None,chatbot,queue=False)\n",
        "\n",
        "    app.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c33dc8a608a4b6f9bef6f07edff80d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e9de5fdd7d74fc1b8bf553dbf8b56cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54309e2d38bf4df8953bc92cecd93ed9",
              "IPY_MODEL_ba3285e294a84338887f60634f56011d",
              "IPY_MODEL_660a926516784b0d8445a924f4241bd0"
            ],
            "layout": "IPY_MODEL_32567f36e10146359382240e95a25a4f"
          }
        },
        "32567f36e10146359382240e95a25a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449d31336daf4547b421b0e9ff38168b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54309e2d38bf4df8953bc92cecd93ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b964d049203448d484d053ba74d4d4df",
            "placeholder": "​",
            "style": "IPY_MODEL_a0ac07d44c174e0eb433663688d29161",
            "value": "Parsing nodes: 100%"
          }
        },
        "660a926516784b0d8445a924f4241bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cad7f9da6c34a589242394eb0db56ef",
            "placeholder": "​",
            "style": "IPY_MODEL_2c33dc8a608a4b6f9bef6f07edff80d7",
            "value": " 10/10 [00:00&lt;00:00, 282.09it/s]"
          }
        },
        "8cad7f9da6c34a589242394eb0db56ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ac07d44c174e0eb433663688d29161": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a31764037e2b45deac32374af85feb4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b964d049203448d484d053ba74d4d4df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3285e294a84338887f60634f56011d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31764037e2b45deac32374af85feb4f",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_449d31336daf4547b421b0e9ff38168b",
            "value": 10
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
